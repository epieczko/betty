{
  "registry_version": "1.0.0",
  "generated_at": "2025-11-01T16:58:49.266602+00:00",
  "agents": [
    {
      "name": "api.designer",
      "version": "0.1.0",
      "description": "Design RESTful APIs following enterprise guidelines with iterative refinement",
      "reasoning_mode": "iterative",
      "skills_available": [
        "api.define",
        "api.validate",
        "api.generatemodels",
        "api.compatibility"
      ],
      "capabilities": [
        "Design RESTful APIs from natural language requirements",
        "Apply Zalando guidelines automatically",
        "Generate OpenAPI 3.1 specs with best practices",
        "Iteratively refine based on validation feedback",
        "Handle AsyncAPI for event-driven architectures"
      ],
      "status": "draft",
      "tags": [
        "api",
        "design",
        "openapi",
        "zalando",
        "iterative"
      ],
      "dependencies": [
        "context.schema"
      ]
    },
    {
      "name": "api.analyzer",
      "version": "0.1.0",
      "description": "Analyze API specifications for backward compatibility and breaking changes",
      "reasoning_mode": "oneshot",
      "skills_available": [
        "api.compatibility",
        "api.validate"
      ],
      "capabilities": [
        "Detect breaking changes between API versions",
        "Generate detailed compatibility reports",
        "Identify removed or modified endpoints",
        "Suggest migration paths for breaking changes",
        "Validate API evolution best practices"
      ],
      "status": "draft",
      "tags": [
        "api",
        "analysis",
        "compatibility",
        "versioning",
        "oneshot"
      ],
      "dependencies": []
    },
    {
      "name": "api.architect",
      "version": "0.1.0",
      "description": "An agent that designs comprehensive REST APIs and validates them against best practices. Takes API requirements as input and produces validated OpenAPI specifications with generated data models ready for implementation.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "workflow.validate",
        "api.validate",
        "api.define"
      ],
      "capabilities": [
        "Translate API requirements into detailed OpenAPI specifications",
        "Validate API designs against organizational standards and linting rules",
        "Generate reference data models to accelerate implementation"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "code.reviewer",
      "version": "0.1.0",
      "description": "Analyzes code changes and provides comprehensive feedback on code quality, security vulnerabilities, performance issues, and adherence to best practices.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "code.format",
        "test.workflow.integration",
        "policy.enforce"
      ],
      "capabilities": [
        "Review diffs for quality, security, and maintainability concerns",
        "Generate prioritized issue lists with remediation guidance",
        "Summarize overall code health and compliance with standards"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "data.architect",
      "version": "0.1.0",
      "description": "Create comprehensive data architecture and governance artifacts including data models, schema definitions, data flow diagrams, data dictionaries, data governance policies, and data quality frameworks. Applies data management best practices (DMBOK, DAMA) and ensures artifacts support data-driven decision making, compliance, and analytics initiatives.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Design logical and physical data architectures to support analytics strategies",
        "Define governance policies and quality controls for critical data assets",
        "Produce documentation that aligns stakeholders on data flows and ownership"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "data.validator",
      "version": "0.1.0",
      "description": "Validates data files against schemas, business rules, and data quality standards. Ensures data integrity, completeness, and compliance.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "workflow.validate",
        "api.validate"
      ],
      "capabilities": [
        "Validate datasets against structural and semantic rules",
        "Generate detailed issue reports with remediation recommendations",
        "Track quality metrics and highlight compliance gaps"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "deployment.engineer",
      "version": "0.1.0",
      "description": "Create comprehensive deployment and release artifacts including deployment plans, CI/CD pipelines, release checklists, rollback procedures, runbooks, and infrastructure-as-code configurations. Applies deployment best practices (blue-green, canary, rolling) and ensures safe, reliable production deployments with proper monitoring and rollback capabilities.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Design deployment strategies with rollback and validation procedures",
        "Automate delivery pipelines and operational runbooks",
        "Coordinate release governance, approvals, and compliance requirements"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "file.processor",
      "version": "0.1.0",
      "description": "Processes files through various transformations including format conversion, compression, encryption, and batch operations.",
      "reasoning_mode": "oneshot",
      "skills_available": [
        "file.compare",
        "workflow.orchestrate",
        "build.optimize"
      ],
      "capabilities": [
        "Execute configurable pipelines of file transformations",
        "Optimize files through compression and format conversion workflows",
        "Apply encryption and verification steps with detailed reporting"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "governance.manager",
      "version": "0.1.0",
      "description": "Create comprehensive program and project governance artifacts including project charters, RAID logs (Risks, Assumptions, Issues, Decisions), decision logs, governance frameworks, compliance matrices, and steering committee artifacts. Applies governance frameworks (PMBOK, PRINCE2, COBIT) to ensure proper oversight, accountability, and compliance for programs and projects.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Establish governance structures and stakeholder engagement plans",
        "Maintain comprehensive RAID and decision logs for executive visibility",
        "Ensure compliance with regulatory and organizational policy requirements"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.artifact",
      "version": "0.1.0",
      "description": "The artifact standards authority - THE single source of truth for all\nartifact type definitions in Betty Framework.\n\nThis meta-agent manages the complete lifecycle of artifact types:\n- Defines new artifact types with JSON schemas\n- Updates ARTIFACT_STANDARDS.md documentation\n- Registers types in the artifact registry\n- Validates artifact compatibility across the system\n- Ensures consistency and prevents conflicts\n\nAll artifact types MUST be registered through meta.artifact before use.\nNo ad-hoc artifact definitions are permitted.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.define",
        "registry.update",
        "registry.query"
      ],
      "capabilities": [
        "Curate and register canonical artifact type definitions and schemas",
        "Synchronize documentation with changes to artifact standards",
        "Validate artifact compatibility across registries and manifests"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.command",
      "version": "0.1.0",
      "description": "Creates complete command manifests from natural language descriptions.\n\nThis meta-agent transforms command descriptions into production-ready command\nmanifests that can be registered in the Betty Framework Command Registry.\n\nCommand manifests can delegate to:\n- Agents: For intelligent, context-aware operations\n- Skills: For direct, atomic operations\n- Workflows: For orchestrated multi-step processes\n\nThe meta.command agent generates properly structured YAML manifests with:\n- Command name and metadata\n- Parameter definitions with types and validation\n- Execution configuration (agent/skill/workflow)\n- Documentation and examples\n\nAfter creation, commands can be registered using the command.define skill.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "command.define",
        "artifact.define"
      ],
      "capabilities": [
        "Transform natural language specifications into validated command manifests",
        "Recommend appropriate execution targets across agents, skills, and workflows",
        "Produce documentation and registration-ready assets for new commands"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.compatibility",
      "version": "0.1.0",
      "description": "Analyzes agent and skill compatibility to discover multi-agent workflows.\n\nThis meta-agent helps Claude discover which agents can work together by\nanalyzing artifact flows - what agents produce and what others consume.\n\nEnables intelligent orchestration by suggesting compatible agent combinations\nand detecting potential pipeline gaps.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "agent.compose",
        "artifact.define"
      ],
      "capabilities": [
        "Build compatibility graphs that connect agent inputs and outputs",
        "Recommend orchestrated workflows that minimize gaps and conflicts",
        "Surface registry insights to guide creation of missing capabilities"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.create",
      "version": "0.1.0",
      "description": "Orchestrator meta-agent that intelligently creates skills, commands, and agents.\n\nCapabilities:\n- Detects component type from description\n- Checks inventory for duplicates\n- Analyzes complexity and determines creation pattern\n- Creates skills, commands, and agents in proper order\n- Validates compatibility using meta.compatibility\n- Identifies gaps and provides recommendations\n- Supports auto-filling missing dependencies\n\nThis is the primary entry point for creating Betty components from natural\nlanguage descriptions.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "registry.query",
        "agent.compose"
      ],
      "capabilities": [
        "Diagnose component needs and recommend skills, commands, or agents to create",
        "Generate scaffolding for new framework components with proper metadata",
        "Coordinate validation steps to ensure compatibility before registration"
      ],
      "status": "draft",
      "tags": [
        "meta",
        "orchestration",
        "creation",
        "automation"
      ],
      "dependencies": []
    },
    {
      "name": "meta.hook",
      "version": "0.1.0",
      "description": "Hook creator meta-agent that generates Claude Code hooks from descriptions",
      "reasoning_mode": "iterative",
      "skills_available": [
        "hook.define",
        "hook.register",
        "hook.simulate"
      ],
      "capabilities": [
        "Translate natural language specifications into validated hook manifests",
        "Recommend appropriate hook events, commands, and execution patterns",
        "Simulate and document hook behavior for developer adoption"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.suggest",
      "version": "0.1.0",
      "description": "Context-aware next-step recommender that helps Claude decide what to do next\nafter an agent completes.\n\nAnalyzes current context, produced artifacts, and project state to suggest\ncompatible agents and workflows. Works with meta.compatibility to provide\nintelligent orchestration recommendations.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "meta.compatibility",
        "artifact.define"
      ],
      "capabilities": [
        "Analyze produced artifacts to understand project context",
        "Recommend next agents or workflows with supporting rationale",
        "Highlight gaps and dependencies to maintain delivery momentum"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "security.architect",
      "version": "0.1.0",
      "description": "Create comprehensive security architecture and assessment artifacts including threat models, security architecture diagrams, penetration testing reports, vulnerability management plans, and incident response plans. Applies security frameworks (STRIDE, NIST, ISO 27001, OWASP) and creates artifacts ready for security review and compliance audit.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Perform structured threat modeling and control gap assessments",
        "Produce security architecture and testing documentation for reviews",
        "Recommend remediation and governance improvements for security programs"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "strategy.architect",
      "version": "0.1.0",
      "description": "Create comprehensive business strategy and planning artifacts including business cases, portfolio roadmaps, market analyses, competitive assessments, and strategic planning documents. Leverages financial modeling (NPV, IRR, ROI) and industry frameworks (PMBOK, SAFe, BCG Matrix) to produce executive-ready strategic deliverables.",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Build financial models and strategic roadmaps aligned to business objectives",
        "Analyze market and competitive data to inform executive decisions",
        "Produce governance-ready artifacts with risks, dependencies, and recommendations"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "test.engineer",
      "version": "0.1.0",
      "description": "Create comprehensive testing artifacts including test plans, test cases, test results, test automation strategies, and quality assurance reports. Applies testing methodologies (TDD, BDD, risk-based testing) and frameworks (ISO 29119, ISTQB) to ensure thorough test coverage and quality validation across all test levels (unit, integration, system, acceptance).",
      "reasoning_mode": "iterative",
      "skills_available": [
        "artifact.create",
        "artifact.validate",
        "artifact.review"
      ],
      "capabilities": [
        "Develop comprehensive test strategies across multiple levels and techniques",
        "Produce reusable automation assets and coverage reporting",
        "Analyze defect data to recommend quality improvements"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.agent",
      "version": "0.1.0",
      "description": "Meta-agent that creates other agents by composing skills based on natural\nlanguage descriptions. Transforms natural language descriptions into complete,\nfunctional agents.\n\nmeta.agent analyzes agent requirements, recommends compatible skills using artifact\nmetadata, generates complete agent definitions, and produces documentation.\n",
      "reasoning_mode": "iterative",
      "skills_available": [
        "agent.compose",
        "artifact.define",
        "registry.update"
      ],
      "capabilities": [
        "Analyze agent requirements and identify compatible skills and capabilities",
        "Generate complete agent manifests, documentation, and supporting assets",
        "Validate registry consistency before registering new agents"
      ],
      "status": "draft",
      "tags": [],
      "dependencies": []
    },
    {
      "name": "meta.skill",
      "version": "0.4.0",
      "description": "Creates complete, functional skills from natural language descriptions.\n\nThis meta-agent transforms skill descriptions into production-ready skills with:\n- Complete skill.yaml definition with validated artifact types\n- Artifact flow analysis showing producers/consumers\n- Production-quality Python implementation with type hints\n- Comprehensive test templates\n- Complete documentation with examples\n- Dependency validation\n- Registry registration with artifact_metadata\n- Discoverability verification\n\nEnsures skills follow Betty Framework conventions and are ready for use in agents.\n\nVersion 0.4.0 adds artifact flow analysis, improved code templates with\ntype hints parsed from skill.yaml, and dependency validation.\n",
      "artifact_metadata": {
        "consumes": [
          {
            "type": "skill-description",
            "file_pattern": "**/skill_description.md",
            "content_type": "text/markdown",
            "description": "Natural language description of skill requirements",
            "schema": "schemas/skill-description.json"
          }
        ],
        "produces": [
          {
            "type": "skill-definition",
            "file_pattern": "skills/*/skill.yaml",
            "content_type": "application/yaml",
            "schema": "schemas/skill-definition.json",
            "description": "Complete skill configuration"
          },
          {
            "type": "skill-implementation",
            "file_pattern": "skills/*/*.py",
            "content_type": "text/x-python",
            "description": "Python implementation with proper structure"
          },
          {
            "type": "skill-tests",
            "file_pattern": "skills/*/test_*.py",
            "content_type": "text/x-python",
            "description": "Test template with example tests"
          },
          {
            "type": "skill-documentation",
            "file_pattern": "skills/*/SKILL.md",
            "content_type": "text/markdown",
            "description": "Skill documentation and usage guide"
          }
        ]
      },
      "status": "draft",
      "reasoning_mode": "iterative",
      "capabilities": [
        "Convert skill concepts into production-ready packages with tests and docs",
        "Ensure generated skills follow registry, artifact, and permission conventions",
        "Coordinate registration and documentation updates for new skills"
      ],
      "skills_available": [
        "skill.create",
        "skill.define",
        "artifact.define",
        "artifact.validate.types"
      ],
      "permissions": [
        "filesystem:read",
        "filesystem:write"
      ],
      "system_prompt": "You are meta.skill, the skill creator for Betty Framework.\n\nYour purpose is to transform natural language skill descriptions into complete,\nproduction-ready skills that follow Betty conventions.\n\n## Your Workflow\n\n1. **Parse Description** - Understand skill requirements\n   - Extract name, purpose, inputs, outputs\n   - Identify artifact types in produces/consumes sections\n   - Identify required permissions\n   - Understand implementation requirements\n\n2. **Validate Artifact Types** - CRITICAL: Verify before generating skill.yaml\n   - Extract ALL artifact types from skill description (produces + consumes sections)\n   - Call artifact.validate.types skill:\n     ```bash\n     python3 skills/artifact.validate.types/artifact_validate_types.py \\\n       --artifact_types '[\"threat-model\", \"data-flow-diagrams\", \"architecture-overview\"]' \\\n       --check_schemas true \\\n       --suggest_alternatives true \\\n       --max_suggestions 3\n     ```\n   - Parse validation results:\n     ```json\n     {\n       \"all_valid\": true/false,\n       \"validation_results\": {\n         \"threat-model\": {\n           \"valid\": true,\n           \"file_pattern\": \"*.threat-model.yaml\",\n           \"content_type\": \"application/yaml\",\n           \"schema\": \"schemas/artifacts/threat-model-schema.json\"\n         }\n       },\n       \"invalid_types\": [\"data-flow-diagram\"],\n       \"suggestions\": {\n         \"data-flow-diagram\": [\n           {\"type\": \"data-flow-diagrams\", \"reason\": \"Plural form\", \"confidence\": \"high\"}\n         ]\n       }\n     }\n     ```\n   - If all_valid == false:\n     \u2192 Display invalid_types and suggestions to user\n     \u2192 Example: \"\u274c Artifact type 'data-flow-diagram' not found. Did you mean 'data-flow-diagrams' (plural, high confidence)?\"\n     \u2192 ASK USER to confirm correct types or provide alternatives\n     \u2192 HALT skill creation until artifact types are validated\n   - If all_valid == true:\n     \u2192 Store validated metadata (file_pattern, content_type, schema) for each type\n     \u2192 Use this exact metadata in Step 3 when generating skill.yaml\n\n3. **Analyze Artifact Flow** - Understand skill's place in ecosystem\n   - For each artifact type the skill produces:\n     \u2192 Search registry for skills that consume this type\n     \u2192 Report: \"\u2705 {artifact_type} will be consumed by: {consuming_skills}\"\n     \u2192 If no consumers: \"\u26a0\ufe0f  {artifact_type} has no consumers yet - consider creating skills that use it\"\n   - For each artifact type the skill consumes:\n     \u2192 Search registry for skills that produce this type\n     \u2192 Report: \"\u2705 {artifact_type} produced by: {producing_skills}\"\n     \u2192 If no producers: \"\u274c {artifact_type} has no producers - user must provide manually or create producer skill first\"\n   - Warn about gaps in artifact flow\n   - Suggest related skills to create for complete workflow\n\n4. **Generate skill.yaml** - Create complete definition with VALIDATED artifact metadata\n   - name: Proper naming (domain.action format)\n   - version: Semantic versioning (e.g., \"0.1.0\")\n   - description: Clear description of what the skill does\n   - inputs: List of input parameters (use empty list [] if none)\n   - outputs: List of output parameters (use empty list [] if none)\n   - status: One of \"draft\", \"active\", or \"deprecated\"\n   - Artifact metadata (produces/consumes)\n   - Permissions\n   - Entrypoints with parameters\n\n5. **Generate Implementation** - Create production-quality Python stub\n   - **Parse skill.yaml inputs** to generate proper argparse CLI:\n     ```python\n     # For each input in skill.yaml:\n     parser.add_argument(\n         '--{input.name}',\n         type={map_type(input.type)},  # string\u2192str, number\u2192int, boolean\u2192bool, array\u2192list\n         required={input.required},\n         default={input.default if not required},\n         help=\"{input.description}\"\n     )\n     ```\n   - **Generate function signature** with type hints from inputs/outputs:\n     ```python\n     def validate_artifact_types(\n         artifact_types: List[str],\n         check_schemas: bool = True,\n         suggest_alternatives: bool = True\n     ) -> Dict[str, Any]:\n         \\\"\\\"\\\"\n         {skill.description}\n\n         Args:\n             artifact_types: {input.description from skill.yaml}\n             check_schemas: {input.description from skill.yaml}\n             ...\n\n         Returns:\n             {output descriptions from skill.yaml}\n         \\\"\\\"\\\"\n     ```\n   - **Include implementation pattern** based on skill type:\n     - Validation skills: load data \u2192 validate \u2192 return results\n     - Generator skills: gather inputs \u2192 process \u2192 save output\n     - Transform skills: load input \u2192 transform \u2192 save output\n   - **Add comprehensive error handling**:\n     ```python\n     except FileNotFoundError as e:\n         logger.error(str(e))\n         print(json.dumps({\"ok\": False, \"error\": str(e)}, indent=2))\n         sys.exit(1)\n     ```\n   - **JSON output structure** matching skill.yaml outputs:\n     ```python\n     result = {\n         \"{output1.name}\": value1,  # From skill.yaml outputs\n         \"{output2.name}\": value2,\n         \"ok\": True,\n         \"status\": \"success\"\n     }\n     print(json.dumps(result, indent=2))\n     ```\n   - Add proper logging setup\n   - Include module docstring with usage example\n\n6. **Generate Tests** - Create test template\n   - Unit test structure\n   - Example test cases\n   - Fixtures\n   - Assertions\n\n7. **Generate Documentation** - Create SKILL.md\n   - Purpose and usage\n   - Input/output examples\n   - Integration with agents\n   - Artifact flow (from Step 3 analysis)\n   - Must include markdown header starting with #\n\n8. **Validate Dependencies** - Check Python packages\n   - For each dependency in skill.yaml:\n     \u2192 Verify package exists on PyPI (if possible)\n     \u2192 Check for known naming issues (e.g., \"yaml\" vs \"pyyaml\")\n     \u2192 Warn about version conflicts with existing skills\n   - Suggest installation command: `pip install {dependencies}`\n   - If dependencies missing, warn but don't block\n\n9. **Register Skill** - Update registry\n   - Call registry.update with skill manifest path\n   - Verify skill appears in registry with artifact_metadata\n   - Confirm skill is discoverable via artifact types\n\n10. **Verify Discoverability** - Final validation\n    - Check skill exists in registry/skills.json\n    - Verify artifact_metadata is complete\n    - Test that agent.compose can discover skill by artifact type\n    - Confirm artifact flow is complete (from Step 3)\n\n## Conventions\n\n**Naming:**\n- Skills: `domain.action` (e.g., `api.validate`, `workflow.compose`)\n- Use lowercase with dots\n- Action should be imperative verb\n\n**Structure:**\n```\nskills/domain.action/\n\u251c\u2500\u2500 skill.yaml           (definition)\n\u251c\u2500\u2500 domain_action.py     (implementation)\n\u251c\u2500\u2500 test_domain_action.py (tests)\n\u2514\u2500\u2500 SKILL.md             (docs)\n```\n\n**Artifact Metadata:**\n- Always define what the skill produces/consumes\n- Use registered artifact types from meta.artifact\n- Include schemas when applicable\n\n**Implementation:**\n- Follow Python best practices\n- Include proper error handling\n- Add logging\n- CLI with argparse\n- JSON output for results\n\n## Quality Standards\n\n- \u2705 Follows Betty conventions (domain.action naming, proper structure)\n- \u2705 All required fields in skill.yaml: name, version, description, inputs, outputs, status\n- \u2705 Artifact types VALIDATED against registry before generation\n- \u2705 Artifact flow ANALYZED (producers/consumers identified)\n- \u2705 Production-quality code with type hints and comprehensive docstrings\n- \u2705 Proper CLI generated from skill.yaml inputs (no TODO placeholders)\n- \u2705 JSON output structure matches skill.yaml outputs\n- \u2705 Dependencies VALIDATED and installation command provided\n- \u2705 Comprehensive test template with fixtures\n- \u2705 SKILL.md with markdown header, examples, and artifact flow\n- \u2705 Registered in registry with complete artifact_metadata\n- \u2705 Passes Pydantic validation\n- \u2705 Discoverable via agent.compose by artifact type\n\n## Error Handling & Recovery\n\n**Artifact Type Not Found:**\n- Search registry/artifact_types.json for similar names\n- Check for singular/plural variants (data-model vs logical-data-model)\n- Suggest alternatives: \"Did you mean: 'data-flow-diagrams', 'dataflow-diagram'?\"\n- ASK USER to confirm or provide correct type\n- DO NOT proceed with invalid artifact types\n\n**File Pattern Mismatch:**\n- Use exact file_pattern from registry\n- Warn user if description specifies different pattern\n- Document correct pattern in skill.yaml comments\n\n**Schema File Missing:**\n- Warn: \"Schema file schemas/artifacts/X-schema.json not found\"\n- Ask if schema should be: (a) created, (b) omitted, (c) ignored\n- Continue with warning but don't block skill creation\n\n**Registry Update Fails:**\n- Report specific error from registry.update\n- Check if it's version conflict or validation issue\n- Provide manual registration command as fallback\n- Log issue for framework team\n\n**Duplicate Skill Name:**\n- Check existing version in registry\n- Offer to: (a) version bump, (b) rename skill, (c) cancel\n- Require explicit user confirmation before overwriting\n\nRemember: You're creating building blocks for agents. Make skills\ncomposable, well-documented, and easy to use. ALWAYS validate artifact\ntypes before generating skill.yaml!\n"
    },
    {
      "name": "meta.config.router",
      "version": "0.1.0",
      "description": "Configure Claude Code Router for Betty to support multi-model LLM routing across environments",
      "status": "active",
      "reasoning_mode": "oneshot",
      "capabilities": [
        "Generate multi-model LLM router configurations",
        "Validate router configuration inputs for correctness",
        "Apply configurations to filesystem with audit trails",
        "Support multiple output modes (preview, file, both)",
        "Work across local, cloud, and CI environments"
      ],
      "skills_available": [
        "config.validate.router",
        "config.generate.router",
        "audit.log"
      ],
      "permissions": [
        "filesystem:read",
        "filesystem:write"
      ],
      "tags": [
        "llm",
        "router",
        "configuration",
        "meta",
        "infra"
      ],
      "updated_at": "2025-11-01T16:58:49.266564+00:00"
    }
  ]
}