# Safety Filter Configurations
# See also: artifact_descriptions/safety-filter-configurations.md for complete guidance

# The Safety Filter Configurations artifact defines content moderation policies, toxicity thresholds, PII detection rules, and jailbreak prevention mechanisms for AI systems and user-generated content p

metadata:
  # Document Control
  version: "1.0.0"  # Semantic versioning (MAJOR.MINOR.PATCH)
  created: "YYYY-MM-DD"  # Date this artifact was created
  lastModified: "YYYY-MM-DD"  # Date of most recent update
  status: "Draft"  # Draft | Review | Approved | Published | Deprecated

  # Ownership & Accountability
  author: "Author Name"  # Primary author of this artifact
  documentOwner: "Owner Role/Name"  # Person/role responsible for maintenance
  classification: "Internal"  # Public | Internal | Confidential | Restricted

  # Approvals
  approvers:
    - name: "Approver Name"
      role: "Approver Role"
      approvalDate: null  # Date of approval (YYYY-MM-DD)

# PURPOSE
# This artifact establishes comprehensive content safety configurations that filter harmful, toxic, or inappropriate content from AI system inputs and outputs, protect sensitive user information through PII detection, and prevent adversarial attacks through jailbreak detection. It defines the rules, t...

# MAIN CONTENT
# Complete the sections below based on your specific artifact needs

# BEST PRACTICES:
# - Start Conservative: Begin with strict thresholds (0.8-0.9) and relax based on false positive data, not vice versa
# - Multi-Layer Defense: Implement both input and output filtering; never rely on single layer
# - Monitor False Positives: Track and review false positive cases to tune thresholds appropriately
# - Context-Aware Filtering: Adjust thresholds based on context (public vs. private, user demographics)
# - Fail Safe: On API failures, default to safe behavior (block on uncertainty or defer to human review)

content:
  overview: |
    # Provide a high-level overview of this artifact
    # What is this document about?
    # Why does it exist?
    
  scope:
    inScope:
      - "Content moderation policies and toxicity thresholds"
      - "Perspective API configuration (toxicity, severe toxicity, identity attack, profanity)"
      - "Azure Content Safety severity levels and categories"
      # Add additional in-scope items
    outOfScope:
      - "Item explicitly out of scope"
      # Add additional out-of-scope items

  details: |
    # Provide detailed information specific to this artifact type
    # Include all necessary technical details
    # Reference the artifact description for required sections
    
# QUALITY CHECKLIST
# Before finalizing, verify:
# ✓ Completeness: All required sections present and adequately detailed
# ✓ Accuracy: Information verified and validated by appropriate subject matter experts
# ✓ Clarity: Written in clear, unambiguous language appropriate for intended audience
# ✓ Consistency: Aligns with organizational standards, templates, and related artifacts
# ✓ Currency: Based on current information; outdated content removed or updated

relatedDocuments:
  - type: "Related Artifact Type"
    path: "path/to/related/artifact"
    relationship: "depends-on | references | supersedes | implements"

changeHistory:
  - version: "1.0.0"
    date: "YYYY-MM-DD"
    author: "Author Name"
    changes: "Initial version"
