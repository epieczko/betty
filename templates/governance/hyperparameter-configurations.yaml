# Hyperparameter Configurations
# See also: artifact_descriptions/hyperparameter-configurations.md for complete guidance

# The Hyperparameter Configurations artifact documents the hyperparameter search space, optimization methodology, tuning results, and final parameter selections for ML models. This artifact enables repr

metadata:
  # Document Control
  version: "1.0.0"  # Semantic versioning (MAJOR.MINOR.PATCH)
  created: "YYYY-MM-DD"  # Date this artifact was created
  lastModified: "YYYY-MM-DD"  # Date of most recent update
  status: "Draft"  # Draft | Review | Approved | Published | Deprecated

  # Ownership & Accountability
  author: "Author Name"  # Primary author of this artifact
  documentOwner: "Owner Role/Name"  # Person/role responsible for maintenance
  classification: "Internal"  # Public | Internal | Confidential | Restricted

  # Approvals
  approvers:
    - name: "Approver Name"
      role: "Approver Role"
      approvalDate: null  # Date of approval (YYYY-MM-DD)

# PURPOSE
# This artifact documents hyperparameter search space, optimization strategy, tuning experiments, and final parameter selections to enable reproducible model training, justify modeling decisions, and provide audit trail for model governance. It serves as technical documentation for model deployment an...

# MAIN CONTENT
# Complete the sections below based on your specific artifact needs

# BEST PRACTICES:
# - Bayesian Over Random: Prefer Bayesian optimization (Optuna, Ray Tune with TPE) over random search for sample-efficient tun
# - Log Everything: Log all hyperparameters, metrics, and artifacts to MLflow or W&B; enable experiment comparison
# - Fixed Random Seeds: Always set random seeds for NumPy, TensorFlow, PyTorch, scikit-learn for reproducibility
# - Search Space Design: Use log-uniform distributions for learning rates, exponential distributions for batch sizes
# - Sufficient Budget: Allocate sufficient trials (50-100+ for Bayesian, 1000+ for random search) before declaring converge

content:
  overview: |
    # Provide a high-level overview of this artifact
    # What is this document about?
    # Why does it exist?
    
  scope:
    inScope:
      - "Hyperparameter search space"
      - "Optimization methodology"
      - "Tuning framework"
      # Add additional in-scope items
    outOfScope:
      - "Item explicitly out of scope"
      # Add additional out-of-scope items

  details: |
    # Provide detailed information specific to this artifact type
    # Include all necessary technical details
    # Reference the artifact description for required sections
    
# QUALITY CHECKLIST
# Before finalizing, verify:
# ✓ Completeness: All required sections present and adequately detailed
# ✓ Accuracy: Information verified and validated by appropriate subject matter experts
# ✓ Clarity: Written in clear, unambiguous language appropriate for intended audience
# ✓ Consistency: Aligns with organizational standards, templates, and related artifacts
# ✓ Currency: Based on current information; outdated content removed or updated

relatedDocuments:
  - type: "Related Artifact Type"
    path: "path/to/related/artifact"
    relationship: "depends-on | references | supersedes | implements"

changeHistory:
  - version: "1.0.0"
    date: "YYYY-MM-DD"
    author: "Author Name"
    changes: "Initial version"
