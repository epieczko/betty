# Data Lineage Tracking
# See also: artifact_descriptions/data-lineage-tracking.md for complete guidance

# Data Lineage Tracking is the operational process and technical implementation for continuously capturing, updating, and maintaining data lineage metadata in real-time as data flows through pipelines, 

metadata:
  # Document Control
  version: "1.0.0"  # Semantic versioning (MAJOR.MINOR.PATCH)
  created: "YYYY-MM-DD"  # Date this artifact was created
  lastModified: "YYYY-MM-DD"  # Date of most recent update
  status: "Draft"  # Draft | Review | Approved | Published | Deprecated

  # Ownership & Accountability
  author: "Author Name"  # Primary author of this artifact
  documentOwner: "Owner Role/Name"  # Person/role responsible for maintenance
  classification: "Internal"  # Public | Internal | Confidential | Restricted

  # Approvals
  approvers:
    - name: "Approver Name"
      role: "Approver Role"
      approvalDate: null  # Date of approval (YYYY-MM-DD)

# PURPOSE
# This artifact documents the technical implementation, configuration, and operational procedures for automated data lineage capture, including instrumentation code, event schemas, metadata extraction schedules, and integration patterns with data platforms and catalog systems....

# MAIN CONTENT
# Complete the sections below based on your specific artifact needs

# BEST PRACTICES:
# - Infrastructure as Code: Deploy lineage tracking configuration (DataHub recipes, Atlas hooks, OpenLineage configs) using Terr
# - OpenLineage First: Prioritize OpenLineage standard for new integrations to ensure portability across lineage tools and 
# - Event-Driven Architecture: Design lineage capture as event-driven using Kafka, AWS EventBridge, or Azure Event Grid for scalabi
# - Column-Level Instrumentation: Implement SQL parsing (sqlglot, sqlparse, JSQLParser) for automatic column-level lineage extraction
# - Idempotent Events: Ensure lineage events are idempotent to handle retries and avoid duplicate metadata creation

content:
  overview: |
    # Provide a high-level overview of this artifact
    # What is this document about?
    # Why does it exist?
    
  scope:
    inScope:
      - "OpenLineage event emission configuration for Apache Airflow, Spark, dbt, and custom pipelines"
      - "Apache Atlas hook implementation for Hive, HBase, Kafka, and Hadoop ecosystem lineage"
      - "DataHub metadata ingestion recipes and scheduled extraction from databases, ETL tools, and BI platforms"
      # Add additional in-scope items
    outOfScope:
      - "Item explicitly out of scope"
      # Add additional out-of-scope items

  details: |
    # Provide detailed information specific to this artifact type
    # Include all necessary technical details
    # Reference the artifact description for required sections
    
# QUALITY CHECKLIST
# Before finalizing, verify:
# ✓ Completeness: All required sections present and adequately detailed
# ✓ Accuracy: Information verified and validated by appropriate subject matter experts
# ✓ Clarity: Written in clear, unambiguous language appropriate for intended audience
# ✓ Consistency: Aligns with organizational standards, templates, and related artifacts
# ✓ Currency: Based on current information; outdated content removed or updated

relatedDocuments:
  - type: "Related Artifact Type"
    path: "path/to/related/artifact"
    relationship: "depends-on | references | supersedes | implements"

changeHistory:
  - version: "1.0.0"
    date: "YYYY-MM-DD"
    author: "Author Name"
    changes: "Initial version"
